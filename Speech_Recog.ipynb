{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e10dc15-dbdb-4f8b-a5a2-d761a8eaea71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72b83878-aaf7-4d9c-9073-af61fed55c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\pawan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\pawan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "053f1f9c-3a71-4fef-aaa0-4574c99f46b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fb4e683-55c1-4afe-8613-73b8f3c3c588",
   "metadata": {
    "papermill": {
     "duration": 0.045429,
     "end_time": "2021-08-04T11:54:34.061714",
     "exception": false,
     "start_time": "2021-08-04T11:54:34.016285",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def lower_text(text):\n",
    "    return text.lower()\n",
    "\n",
    "def remove_number(text):\n",
    "    num = re.compile(r'[-+]?[.\\d]*[\\d]+[:,.\\d]*')\n",
    "    return num.sub(r'', text)\n",
    "\n",
    "def remove_punct(text):\n",
    "    punctuations = string.punctuation \n",
    "    \n",
    "    for p in punctuations:\n",
    "        text = text.replace(p, '')\n",
    "    return text\n",
    "    \n",
    "def remove_stopwords(text):\n",
    "    text = ' '.join([word for word in text.split() if word not in (stopwords)])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "141b0f00-fef3-457d-9273-445f16e4fcc3",
   "metadata": {
    "papermill": {
     "duration": 0.04323,
     "end_time": "2021-08-04T11:54:34.140070",
     "exception": false,
     "start_time": "2021-08-04T11:54:34.096840",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = lower_text(text)\n",
    "    text = remove_number(text)\n",
    "    text = remove_punct(text)\n",
    "    text = remove_stopwords(text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6874f7ba-7fe6-4aed-b747-c36aaa5bc3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"emotion_model_29_01_2023.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec5f3de1-f39d-417b-ace9-25740828440f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_text = clean_text('lmao dead rofl ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6051fb2-148d-468b-aba7-cf75fce681b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = {0:\"anger\", 1:\"fear\", 2:\"joy\", 3:\"love\", 4:\"sadness\", 5:\"surprise\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5c257a9-ee57-4c22-bd73-2185b21fa79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tokenizer.pkl', 'rb') as file:\n",
    "    tokenizer = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ea2886b-d7ca-4d25-a6d4-a2baed5efd33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1048    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "aa = tokenizer.texts_to_sequences([cleaned_text])\n",
    "aa = pad_sequences(aa, padding='post', maxlen=35)\n",
    "print(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61c3c67b-0eeb-4e75-aacc-a2fc77497ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 511ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(model.predict(aa), axis = 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "024d2052-e7ed-437b-8b13-71a3a52e97b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'fear'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.get(np.argmax(model.predict(aa), axis = 1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d1f3d36-2be9-4a0b-ac5a-e9f1a56d088a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def emotion_predictor(cleaned_text):\n",
    "    print(cleaned_text)\n",
    "    text_to_seq = tokenizer.texts_to_sequences([cleaned_text])    \n",
    "    print(text_to_seq)\n",
    "\n",
    "    text_to_seq = pad_sequences(text_to_seq, padding='post', maxlen=35)\n",
    "    print(text_to_seq)\n",
    "\n",
    "    return encoder.get(np.argmax(model.predict(text_to_seq), axis = 1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "11582a9d-a7bb-42de-b96f-aacae4628d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "request give another chance\n",
      "[[6788, 117, 158, 762]]\n",
      "[[6788  117  158  762    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0]]\n",
      "1/1 [==============================] - 0s 24ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'anger'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_text = clean_text(\"\")\n",
    "emotion_predictor(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b98aace-aae3-49ec-93b8-5b0c02e17489",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "114b792fd3786b6575d0460937c918251b05a94eee91cfbf04c710c56ed0b84d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
