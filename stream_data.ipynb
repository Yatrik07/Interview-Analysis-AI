{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\,Msc\\AU Hackathon\\ing_2023_env\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "The torchaudio backend is switched to 'soundfile'. Note that 'sox_io' is not supported on Windows.\n",
      "torchvision is not available - cannot save figures\n",
      "The torchaudio backend is switched to 'soundfile'. Note that 'sox_io' is not supported on Windows.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import pickle\n",
    "import librosa\n",
    "import shutil\n",
    "os.environ[\"TRANSFORMERS_OFFLINE\"] = \"1\"\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from collections import Counter\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from pydub import AudioSegment\n",
    "from typing import List, Tuple\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "import wave\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "# load model and processor\n",
    "from speechbrain.pretrained.interfaces import foreign_class\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "\n",
    "def crop(img, x, y, width, height):\n",
    "    return img[y:y+height, x:x+width]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES_EMO_FACE = {0: \"Angry\", 1: \"Disgusted\", 2: \"Fearful\", 3: \"Happy\", 4: \"Neutral\", 5: \"Sad\", 6: \"Surprised\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def post_process(predicts):\n",
    "#     if np.argmax(predicts) == 3:\n",
    "#         return CLASSES_EMO_FACE[3]\n",
    "#     elif np.argmax(predicts) == 4:\n",
    "#         print(predicts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_predict(img, model):\n",
    "\n",
    "    img = cv2.resize(img, (48, 48))\n",
    "    # cv2.imshow(\"Face\", img)\n",
    "    # cv2.waitKey(0)\n",
    "    img = img/255\n",
    "    img = np.expand_dims(img, axis=2)\n",
    "    # print(img.shape)\n",
    "    predicts = model.predict(np.expand_dims(img, axis = 0), verbose = 0)\n",
    "    # post_process(predicts)\n",
    "    return CLASSES_EMO_FACE[np.argmax(predicts[0])]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "\n",
    "# model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(48,48,1)))\n",
    "# model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.25))\n",
    "\n",
    "# model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Conv2D(128, kernel_size=(3, 3), activatio\n",
    "# n='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.25))\n",
    "\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(1024, activation='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(7, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "VIDEO_PATH = 0\n",
    "FACE_CASCADE = cv2.CascadeClassifier(\"haarcascade_face.xml\") \n",
    "FACE_EMOTION_MODEL_PATH = \"model_mv1.h5\"\n",
    "\n",
    "FACE_EMOTION_MODEL = tf.keras.models.load_model(FACE_EMOTION_MODEL_PATH)\n",
    "# model.load_weights(FACE_EMOTION_MODEL_PATH)\n",
    "# FACE_EMOTION_MODEL = model\n",
    "RESIZE_SIZES = {\n",
    "    \"single\":(50, 50),\n",
    "    \"double\":(100, 50)\n",
    "}\n",
    "neutral = True\n",
    "happy = True\n",
    "RESIZE = True\n",
    "FACE_PERC = 0.6\n",
    "N_FPS = 1\n",
    "SHOW = False\n",
    "\n",
    "EYE_CASCADE = cv2.CascadeClassifier(\"haarcascade_eye.xml\")  # capture frames from a camera \n",
    "MODE = \"rgb\"\n",
    "def face_eye_emotion(video_path:str, face_perc:float, n_fps:int, resize:bool, show:bool, mode:str, resize_sizes:dict, emotion_model):\n",
    "    cap = cv2.VideoCapture(video_path) \n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    neutral = True\n",
    "    happy = True\n",
    "    if not cap.isOpened():\n",
    "        return f\"Unable to read given file {video_path}\"\n",
    "    val = int(fps/N_FPS)\n",
    "    eyes_list = []\n",
    "    both_eyes = []\n",
    "    no_face = 0\n",
    "    no_eyes = 0\n",
    "    face_emotions = {}\n",
    "    assert mode in  [\"gray\", \"rgb\"], f\"mode must be either gray or rgb not {mode}\"\n",
    "    # loop runs if capturing has been initialized. \n",
    "    while 1:  \n",
    "        # reads frames from a camera \n",
    "        ret, img = cap.read()  \n",
    "        fno = int(cap.get(1))\n",
    "        if not ret:\n",
    "            break   \n",
    "        # print(\"here\")\n",
    "        if fno % val != 0:\n",
    "            continue\n",
    "        # convert to gray scale of each frames \n",
    "        # cv2.imshow('img',img)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) \n",
    "        # print(fno)\n",
    "        # Detects faces of different sizes in the input image \n",
    "        faces = FACE_CASCADE.detectMultiScale(gray, 1.3, 5) \n",
    "        if len(faces) < 1:\n",
    "            # print(\"no_face\")\n",
    "            no_face += 1\n",
    "            face_emotions[fno] =None\n",
    "            continue\n",
    "        \n",
    "        # cv2.imshow('img',img)\n",
    "        for (x,y,w,h) in faces[:1]: \n",
    "            # To draw a rectangle in a facee  \n",
    "            # cv2.rectangle(img,(x,y),(x+w,y+h),(255,255,0),2)  \n",
    "            roi_gray = gray[y:y+h, x:x+w] \n",
    "            roi_color = img[y:y+h, x:x+w] \n",
    "\n",
    "            face_emotions[fno] = face_predict(roi_gray, emotion_model)\n",
    "            if neutral:\n",
    "                if face_emotions[fno] == \"Neutral\":\n",
    "                    neut_image = roi_color\n",
    "                    cv2.imwrite(\"static/neutral.jpg\", neut_image)\n",
    "                    neutral = False\n",
    "            if happy:\n",
    "                if face_emotions[fno] == \"Happy\":\n",
    "                    happ_image = roi_color\n",
    "                    cv2.imwrite(\"static/happy.jpg\", happ_image)\n",
    "                    happy = False\n",
    "            # post_process(predicts)\n",
    "            # cv2.imshow('img',img)\n",
    "            # Detects eyes of different sizes in the input image \n",
    "            eyes = EYE_CASCADE.detectMultiScale(roi_gray)  \n",
    "            #To draw a rectangle in eyes \n",
    "            cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255,0),1)\n",
    "            count = 0\n",
    "            ex_list = []\n",
    "            ey_list = []\n",
    "            x_end = []\n",
    "            y_end = []\n",
    "            if len(eyes) < 2:\n",
    "                # eyes_list.append([None, None])\n",
    "                # both_eyes.append(None)\n",
    "                # print(\"no eyes\")\n",
    "                no_eyes += 1\n",
    "                # eyes_list.append([None, None])\n",
    "                # both_eyes.append(None)\n",
    "                continue\n",
    "            temp_list = []\n",
    "            # cv2.imshow('img',img)\n",
    "            for (ex,ey,ew,eh) in eyes:\n",
    "                if ey + eh <= roi_gray.shape[1] * face_perc:\n",
    "                    count += 1\n",
    "                    ex_list.append(ex)\n",
    "                    ey_list.append(ey)\n",
    "                    x_end.append(ex + ew)\n",
    "                    y_end.append(ey + eh)\n",
    "                    if mode == \"gray\":\n",
    "                        temp_list.append(crop(roi_gray, ex, ey, ew, eh))\n",
    "                        cv2.rectangle(roi_gray,(ex,ey),(ex+ew,ey+eh),(0,127,255),2)\n",
    "                    else:\n",
    "                        temp_list.append(crop(roi_color, ex, ey, ew, eh))\n",
    "                        cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,127,255),2)\n",
    "                \n",
    "            \n",
    "        # print(ex_list)\n",
    "        # print(ey_list)\n",
    "        # Display an image in a window\n",
    "        if count >= 2:\n",
    "            if ex_list[0] < ex_list[1]:\n",
    "                pass\n",
    "            else:\n",
    "                # print('swapped')\n",
    "                temp_list[1], temp_list[0] = temp_list[0], temp_list[1]\n",
    "            if RESIZE:\n",
    "                temp_list[0] = cv2.resize(temp_list[0], resize_sizes[\"single\"])\n",
    "                temp_list[1] = cv2.resize(temp_list[1], resize_sizes[\"single\"])\n",
    "            eyes_list.append(temp_list)\n",
    "            # print(2)\n",
    "            if show:\n",
    "                cv2.imshow(\"eye1\",cv2.hconcat([temp_list[0], temp_list[1]]))\n",
    "            # cv2.imshow(\"eye2\",temp_list[1])\n",
    "            min_ex = min(ex_list)\n",
    "            min_ey = min(ey_list)        \n",
    "            max_ex = max(x_end)\n",
    "            max_ey = max(y_end)\n",
    "            # req_w = max_ex - min_ex\n",
    "            # req_h = max_ey - min_ey\n",
    "            # cv2.rectangle(roi_gray,(min_ex,min_ey),(max_ex, max_ey),(0,127,255),2)\n",
    "            if mode == \"gray\":\n",
    "                both = crop(roi_gray, min_ex, min_ey, max_ex - min_ex, max_ey - min_ey)   \n",
    "            else:\n",
    "                both = crop(roi_color, min_ex, min_ey, max_ex - min_ex, max_ey - min_ey)   \n",
    "            if resize:\n",
    "                both = cv2.resize(both, resize_sizes[\"double\"])\n",
    "            both_eyes.append(both)\n",
    "\n",
    "            \n",
    "            if show:\n",
    "                cv2.imshow(\"both_eyes\", both)\n",
    "                cv2.imshow('img',img)\n",
    "                cv2.imshow(\"new\", roi_gray)\n",
    "        else:\n",
    "            # eyes_list.append([None, None])\n",
    "            # both_eyes.append(None)\n",
    "            continue\n",
    "        # Wait for Esc key to stop \n",
    "        # cv2.imshow('img',img)\n",
    "        # print(face_emotions)\n",
    "        k = cv2.waitKey(5)\n",
    "        if k == 27: \n",
    "            break\n",
    "        # cv2.waitKey(0)\n",
    "        # break\n",
    "    \n",
    "    \n",
    "    # Close the window \n",
    "    cap.release() \n",
    "    \n",
    "    # De-allocate any associated memory usage \n",
    "    cv2.destroyAllWindows() \n",
    "    return eyes_list, both_eyes, no_eyes, no_face, face_emotions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "eyes_list, both_eyes, no_eyes, no_face, face_emotion = face_eye_emotion( video_path= \"D:\\,Msc\\AU Hackathon\\merged_new.mp4\", face_perc=FACE_PERC,n_fps= N_FPS,resize= RESIZE,\n",
    "                        show=True, mode= MODE,resize_sizes= RESIZE_SIZES, emotion_model= FACE_EMOTION_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "both_eyes = np.array(list(map(lambda x:x.flatten(), both_eyes)))\n",
    "both_eyes.shape\n",
    "\n",
    "eyes_stacked = list(map(lambda x: np.vstack([x[0], x[1]]).flatten(), eyes_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iso_model = IsolationForest(n_estimators=200)\n",
    "predicts = iso_model.fit_predict(both_eyes)\n",
    "predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process(eyes_list:list, both_eyes:list, use:str, face_emotion:dict, no_eyes, no_face, n_estimators :int = 100,):\n",
    "    emotions = Counter(face_emotion.values())\n",
    "    if use == \"single\":\n",
    "        eyes_stacked = list(map(lambda x: np.vstack([x[0], x[1]]).flatten(), eyes_list))\n",
    "    else:\n",
    "        eyes_stacked = np.array(list(map(lambda x:x.flatten(), both_eyes)))\n",
    "    iso_model = IsolationForest(n_estimators=200)\n",
    "    predicts = iso_model.fit_predict(eyes_stacked)\n",
    "    contact = np.sum(predicts == 1)\n",
    "    perc_conc = contact/ (len(predicts) + no_eyes + no_face) * 100\n",
    "    return {\"Emotion data\" : emotions, \"Attention %\" : perc_conc}\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m post_process(eyes_list\u001b[39m=\u001b[39;49m eyes_list,both_eyes\u001b[39m=\u001b[39;49m both_eyes,use\u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mboth\u001b[39;49m\u001b[39m\"\u001b[39;49m,face_emotion\u001b[39m=\u001b[39;49m face_emotion,no_eyes\u001b[39m=\u001b[39;49m no_eyes,no_face\u001b[39m=\u001b[39;49m no_face)\n",
      "Cell \u001b[1;32mIn[23], line 8\u001b[0m, in \u001b[0;36mpost_process\u001b[1;34m(eyes_list, both_eyes, use, face_emotion, no_eyes, no_face, n_estimators)\u001b[0m\n\u001b[0;32m      6\u001b[0m     eyes_stacked \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(\u001b[39mlist\u001b[39m(\u001b[39mmap\u001b[39m(\u001b[39mlambda\u001b[39;00m x:x\u001b[39m.\u001b[39mflatten(), both_eyes)))\n\u001b[0;32m      7\u001b[0m iso_model \u001b[39m=\u001b[39m IsolationForest(n_estimators\u001b[39m=\u001b[39m\u001b[39m200\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m predicts \u001b[39m=\u001b[39m iso_model\u001b[39m.\u001b[39;49mfit_predict(eyes_stacked)\n\u001b[0;32m      9\u001b[0m contact \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum(predicts \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[0;32m     10\u001b[0m perc_conc \u001b[39m=\u001b[39m contact\u001b[39m/\u001b[39m (\u001b[39mlen\u001b[39m(predicts) \u001b[39m+\u001b[39m no_eyes \u001b[39m+\u001b[39m no_face) \u001b[39m*\u001b[39m \u001b[39m100\u001b[39m\n",
      "File \u001b[1;32md:\\,Msc\\AU Hackathon\\ing_2023_env\\lib\\site-packages\\sklearn\\base.py:978\u001b[0m, in \u001b[0;36mOutlierMixin.fit_predict\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    960\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Perform fit on X and returns labels for X.\u001b[39;00m\n\u001b[0;32m    961\u001b[0m \n\u001b[0;32m    962\u001b[0m \u001b[39mReturns -1 for outliers and 1 for inliers.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    975\u001b[0m \u001b[39m    1 for inliers, -1 for outliers.\u001b[39;00m\n\u001b[0;32m    976\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    977\u001b[0m \u001b[39m# override for transductive outlier detectors like LocalOulierFactor\u001b[39;00m\n\u001b[1;32m--> 978\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(X)\u001b[39m.\u001b[39mpredict(X)\n",
      "File \u001b[1;32md:\\,Msc\\AU Hackathon\\ing_2023_env\\lib\\site-packages\\sklearn\\ensemble\\_iforest.py:290\u001b[0m, in \u001b[0;36mIsolationForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    269\u001b[0m \u001b[39mFit estimator.\u001b[39;00m\n\u001b[0;32m    270\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[39m    Fitted estimator.\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m--> 290\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, accept_sparse\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mcsc\u001b[39;49m\u001b[39m\"\u001b[39;49m], dtype\u001b[39m=\u001b[39;49mtree_dtype)\n\u001b[0;32m    291\u001b[0m \u001b[39mif\u001b[39;00m issparse(X):\n\u001b[0;32m    292\u001b[0m     \u001b[39m# Pre-sort indices to avoid that each individual tree of the\u001b[39;00m\n\u001b[0;32m    293\u001b[0m     \u001b[39m# ensemble sorts the indices.\u001b[39;00m\n\u001b[0;32m    294\u001b[0m     X\u001b[39m.\u001b[39msort_indices()\n",
      "File \u001b[1;32md:\\,Msc\\AU Hackathon\\ing_2023_env\\lib\\site-packages\\sklearn\\base.py:546\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    544\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    545\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 546\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    547\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[0;32m    548\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32md:\\,Msc\\AU Hackathon\\ing_2023_env\\lib\\site-packages\\sklearn\\utils\\validation.py:902\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    900\u001b[0m     \u001b[39m# If input is 1D raise error\u001b[39;00m\n\u001b[0;32m    901\u001b[0m     \u001b[39mif\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 902\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    903\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mExpected 2D array, got 1D array instead:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39marray=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    904\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    905\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    906\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mif it contains a single sample.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[0;32m    907\u001b[0m         )\n\u001b[0;32m    909\u001b[0m \u001b[39mif\u001b[39;00m dtype_numeric \u001b[39mand\u001b[39;00m array\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39min\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mUSV\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    910\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    911\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdtype=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnumeric\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    912\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    913\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "post_process(eyes_list= eyes_list,both_eyes= both_eyes,use= \"both\",face_emotion= face_emotion,no_eyes= no_eyes,no_face= no_face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converts mp4 to wav\n",
    "\n",
    "\n",
    "def convert(mp4_path:str, wav_save_path:str):\n",
    "    assert mp4_path[-3:].lower() == \"mp4\"\n",
    "\n",
    "    # load mp4\n",
    "    audio = AudioSegment.from_file(mp4_path)\n",
    "    \n",
    "    # export to dir\n",
    "    audio.export(wav_save_path, format=\"wav\")\n",
    "\n",
    "    # return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert(\"TCS Campus Interview l Campus Placements l Gauri Shrimali.mp4\", wav_save_path=\"converted_audio1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datasets import load_dataset\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "CHUNK_SIZE = 30\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\", \n",
    "    model=\"openai/whisper-tiny\",\n",
    "    chunk_length_s=CHUNK_SIZE,\n",
    "    device=device,\n",
    ")\n",
    "def speech2text_pipeline(audio_path, pipe, return_df = True):\n",
    "    sample = {}\n",
    "    # sample\n",
    "    sample['path'] = \"./converted_audio.wav\"\n",
    "    sample['array'], sample[\"sampling_rate\"] = librosa.load(\"./converted_audio.wav\", sr=16000)\n",
    "    prediction = pipe(sample, return_timestamps=True)[\"chunks\"]\n",
    "    return pd.DataFrame(prediction) if return_df else prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\,Msc\\AU Hackathon\\ing_2023_env\\lib\\site-packages\\transformers\\generation\\utils.py:1273: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 448 (`generation_config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "CONVERTED_PATH = \"./converted_audio.wav\"\n",
    "GET_DF = True\n",
    "convert(\"TCS Campus Interview l Campus Placements l Gauri Shrimali.mp4\", CONVERTED_PATH)\n",
    "\n",
    "text_result = speech2text_pipeline(CONVERTED_PATH, pipe, GET_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_clips(timestamps:List[Tuple], wav_path: str, temp_file=\"temp_clips\"):\n",
    "    # Open the wave file\n",
    "    with wave.open(wav_path, \"rb\") as wave_file:\n",
    "        # Get the number of frames and the frame rate\n",
    "        n_frames = wave_file.getnframes()\n",
    "        frame_rate = wave_file.getframerate()\n",
    "        # print(frame_rate)\n",
    "        # print(frame_rate)\n",
    "        # # frame_rate = wave_file.getframerate()\n",
    "        # print(n_frames, frame_rate)\n",
    "        \n",
    "        # Create the temp folder if it doesn't exist\n",
    "        if not os.path.exists(f\"{temp_file}\"):\n",
    "            os.mkdir(f\"{temp_file}\")\n",
    "        \n",
    "        # Iterate over the start and end times\n",
    "        for i, (start, end) in enumerate(timestamps):\n",
    "            # print(int(start_frame))\n",
    "            # Calculate the start and end frame indices\n",
    "            start_frame = int(start * frame_rate)\n",
    "            end_frame = int(end * frame_rate)\n",
    "            \n",
    "            # print(start, end, start_frame, end_frame)\n",
    "            \n",
    "            # Skip the iteration if the start frame is greater than the end frame\n",
    "            if start_frame >= end_frame:\n",
    "                continue\n",
    "            # print(int(start_frame))\n",
    "            # print(wave_file.getnframes())\n",
    "            # print(start_frame * frame_rate)\n",
    "            # Read the audio data for the specified frame range\n",
    "            try:\n",
    "                wave_file.setpos(start_frame)\n",
    "            except:\n",
    "                continue\n",
    "            audio_data = wave_file.readframes(end_frame - start_frame)\n",
    "            \n",
    "            # Save the audio data to a new wave file\n",
    "            with wave.open(f\"{temp_file}/part{i}.wav\", \"wb\") as output_file:\n",
    "                output_file.setnchannels(wave_file.getnchannels())\n",
    "                output_file.setsampwidth(wave_file.getsampwidth())\n",
    "                output_file.setframerate(frame_rate)\n",
    "                output_file.writeframes(audio_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divide_clips(text_result[\"timestamp\"].values, CONVERTED_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\,Msc\\AU Hackathon\\ing_2023_env\\lib\\site-packages\\transformers\\configuration_utils.py:375: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at facebook/wav2vec2-base were not used when initializing Wav2Vec2Model: ['project_q.bias', 'quantizer.weight_proj.bias', 'project_hid.bias', 'quantizer.weight_proj.weight', 'project_q.weight', 'quantizer.codevectors', 'project_hid.weight']\n",
      "- This IS expected if you are initializing Wav2Vec2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "speechbrain.lobes.models.huggingface_wav2vec - wav2vec 2.0 is frozen.\n"
     ]
    }
   ],
   "source": [
    "classifier = foreign_class(source=\"speechbrain/emotion-recognition-wav2vec2-IEMOCAP\", pymodule_file=\"custom_interface.py\", classname=\"CustomEncoderWav2vec2Classifier\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model and make predictions over all the clips\n",
    "\n",
    "\n",
    "def make_inferences(classifier, remove_dir = True):\n",
    "    # loading model\n",
    "    # make inferences over all the clips\n",
    "    clips_dir = \"./temp_clips/\"\n",
    "    clips = [os.path.join(clips_dir, clip_name) for clip_name in os.listdir(clips_dir)]\n",
    "    text_labs = []\n",
    "    for idx, clip in enumerate(clips):\n",
    "        ti = time.time()\n",
    "        try:\n",
    "            out_prob, score, index, text_lab = classifier.classify_file(clip)\n",
    "        except:\n",
    "            pass\n",
    "        text_labs.append(text_lab[0])\n",
    "        # print(f\"completed part{idx} in {time.time()-ti}\", score.numpy()[0], text_lab[0])\n",
    "    shutil.rmtree(clips_dir)\n",
    "    return text_labs\n",
    "\n",
    "def get_res(key):\n",
    "    if key.lower() == \"hap\":\n",
    "        return \"happy\"\n",
    "    elif key.lower() == \"neu\":\n",
    "        return \"neutral\"\n",
    "    elif key.lower() == \"ang\":\n",
    "        return 'sadness'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sound_results_raw = make_inferences(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'sadness': 52, 'neutral': 166, 'happy': 25})"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sound_results = list(map(get_res, sound_results_raw))\n",
    "sound_results\n",
    "sound_results_final = Counter(sound_results.copy())\n",
    "sound_results_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_text(text):\n",
    "    return text.lower()\n",
    "\n",
    "def remove_number(text):\n",
    "    num = re.compile(r'[-+]?[.\\d]*[\\d]+[:,.\\d]*')\n",
    "    return num.sub(r'', text)\n",
    "\n",
    "def remove_punct(text):\n",
    "    punctuations = string.punctuation \n",
    "    \n",
    "    for p in punctuations:\n",
    "        text = text.replace(p, '')\n",
    "    return text\n",
    "    \n",
    "def remove_stopwords(text):\n",
    "    text = ' '.join([word for word in text.split() if word not in (stop_words)])\n",
    "    return text\n",
    "\n",
    "def clean_text(text):\n",
    "    text = lower_text(text)\n",
    "    text = remove_number(text)\n",
    "    text = remove_punct(text)\n",
    "    text = remove_stopwords(text)\n",
    "    \n",
    "    return text\n",
    "SPEECH_MODEL_PATH = \"emotion_model_29_01_2023.h5\"\n",
    "SPEECH_CLASSIFICATION = tf.keras.models.load_model(SPEECH_MODEL_PATH)\n",
    "encoder = {0:\"anger\", 1:\"fear\", 2:\"joy\", 3:\"love\", 4:\"sadness\", 5:\"surprise\"}\n",
    "\n",
    "with open('tokenizer.pkl', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)\n",
    "\n",
    "def emotion_predictor(cleaned_text):\n",
    "    # print(cleaned_text)\n",
    "    text_to_seq = tokenizer.texts_to_sequences([cleaned_text])    \n",
    "    # print(text_to_seq)\n",
    "\n",
    "    text_to_seq = pad_sequences(text_to_seq, padding='post', maxlen=35)\n",
    "    # print(text_to_seq)\n",
    "\n",
    "    return encoder.get(np.argmax(SPEECH_CLASSIFICATION.predict(text_to_seq, verbose = 0), axis = 1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_speech(df):\n",
    "    res = []\n",
    "    for i in df[\"text\"]:\n",
    "        cleaned = clean_text(i)\n",
    "        res.append({i:emotion_predictor(cleaned)})\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 574ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{' Yes, go ring. Tell me, tell me something old you.': 'joy'},\n",
       " {' Okay, thank you for allowing me to introduce myself. My name is Gauri Shumadi.': 'joy'},\n",
       " {\" I am from Odevo Rajasthan. I'm doing computer science engineering from Gitanjali Institute of Technical Studies.\": 'joy'},\n",
       " {' I secured 9.2 CGPA intense standard 73.4 cg percentage in 12 standard and currently in engineering my aggregates code is 77 percentage.': 'anger'},\n",
       " {' Computer science is omnipresent that is it is present in every field and hence I have invested': 'joy'},\n",
       " {' these last 3.5 almost years in developing my software skills. My technical skills include the programming in Python, Java, C, C++,': 'joy'},\n",
       " {' databases.': 'fear'},\n",
       " {' I am also familiar with web development,': 'fear'},\n",
       " {' Kubernetes, Docker, and Civil, et cetera.': 'sadness'},\n",
       " {' So these are all my technical skills.': 'fear'},\n",
       " {\" And I've also used this skills to build several projects,\": 'fear'},\n",
       " {' which include user management project': 'joy'},\n",
       " {' and attendance management project.': 'fear'},\n",
       " {\" I've also participated in smart India hackathon's,\": 'joy'},\n",
       " {' of which in one we also got to the finals.': 'fear'},\n",
       " {' These all in my technical skills coming to my extra': 'fear'},\n",
       " {' curricular activities.': 'joy'},\n",
       " {' I love to dance, particularly some classical dance.': 'joy'},\n",
       " {' I also like to read, write and paint.': 'sadness'},\n",
       " {' I have been the student editor of our colleges news letter bits and bytes.': 'sadness'},\n",
       " {' And currently I am one of the cultural heads of our students club.': 'joy'},\n",
       " {' So I have also participated in several donation camps.': 'joy'},\n",
       " {' Several donation camps as I am a member of the Rotary Club,': 'joy'},\n",
       " {' or that one.': 'fear'},\n",
       " {' I consider myself as a very focused person,': 'fear'},\n",
       " {' and I always work towards my goals': 'sadness'},\n",
       " {' in a very efficient manner.': 'joy'},\n",
       " {' I am a team player and very optimistic in tough times.': 'joy'},\n",
       " {' And lastly, I would like to say that': 'fear'},\n",
       " {' why not start the journey of my success': 'joy'},\n",
       " {' by the success of joining TCS. Thank you so much.': 'joy'},\n",
       " {' Okay. What are the five specific points about TCS which makes TCS different from other': 'fear'},\n",
       " {' idea of lenses? Firstly, so TCS has a blind name.': 'fear'},\n",
       " {' It is known, it is a multinational company and it has a very good brand name.': 'joy'},\n",
       " {\" And that's it would give me a good start for my career.\": 'fear'},\n",
       " {' Secondly, it has a work-life balance.': 'fear'},\n",
       " {' I have talked to many of my friends who are in TCS and they say that TCS gives a very good work like balance.': 'joy'},\n",
       " {' So that is the second point.': 'fear'},\n",
       " {' Third point is the colleagues there,': 'anger'},\n",
       " {' are very futuristic in their skills.': 'fear'},\n",
       " {' So there is a lot to learn from them.': 'fear'},\n",
       " {' Fourthly, as TCS is a multinational company,': 'fear'},\n",
       " {' I would like to have the chance to even go abroad': 'joy'},\n",
       " {' and meet people of different nationalities.': 'fear'},\n",
       " {' And lastly, there are as TCS has been in the industry for almost 150 years.': 'sadness'},\n",
       " {' So it gives me a sense of job security to some extent.': 'fear'},\n",
       " {' Okay, what are the ethical values TCS have?': 'joy'},\n",
       " {' So, like I said, there is a work life balance and it promotes like gender equality, there is': 'fear'},\n",
       " {' no discrimination on the basis of that.': 'fear'},\n",
       " {' So, it is very good in ethics overall.': 'joy'},\n",
       " {' Okay.': 'fear'},\n",
       " {' Okay, Gwari. Nice to have you.': 'fear'},\n",
       " {' Thank you.': 'fear'},\n",
       " {' Thank you.': 'fear'},\n",
       " {' Can I have a little closer?': 'joy'},\n",
       " {' Good day next part of the interview, right?': 'fear'},\n",
       " {' Thank you so much sir.': 'joy'},\n",
       " {' Good afternoon sir.': 'joy'},\n",
       " {' Good afternoon sir.': 'joy'},\n",
       " {' All good.': 'joy'},\n",
       " {' Yes sir.': 'joy'},\n",
       " {' Okay.': 'fear'},\n",
       " {' Tell us which other campus interviews have you appeared for and what has been the results?': 'fear'},\n",
       " {' So I have interviewed for Jarlanet, which is in the depot only, and I got selected for it.': 'joy'},\n",
       " {' I also interviewed for Gateway Industries. I was not selected in the interview. I got to the interview part, but was not selected.': 'joy'},\n",
       " {\" So that's it. I've only given these interviews. Okay. Have you\": 'fear'},\n",
       " {\" analyzed why you didn't get selected for gateway? So in gateway I might have not answered\": 'love'},\n",
       " {' the technical questions very well as compared to the other candidates. Okay. So how have you prepared for the current ECS interview noise?': 'joy'},\n",
       " {' So, I have enhanced my technical skills, I have been preparing for the course subjects': 'fear'},\n",
       " {' and I have been doing coding almost every day.': 'sadness'},\n",
       " {' So, I think that I have prepared quite well for ECS.': 'joy'},\n",
       " {' Okay.': 'fear'},\n",
       " {' Uh,': 'fear'},\n",
       " {' body tell me what are your future plans?': 'anger'},\n",
       " {' So my future plans. So if I join TCS or otherwise.': 'anger'},\n",
       " {' What are your future plans?': 'anger'},\n",
       " {' So I want to join a software company and work for it.': 'joy'},\n",
       " {\" And I want to learn as much, like as much languages and as much skills as I can and I also want to achieve great success so that I'm satisfied with what I've learned.\": 'joy'},\n",
       " {' Okay.': 'fear'},\n",
       " {' What do you think other reasons for youngsters switching over jobs.': 'sadness'},\n",
       " {' So, maybe it is a job satisfaction because they enter a company without seeing the background': 'joy'},\n",
       " {' of the company and then they later find out that the company was not suitable for them.': 'fear'},\n",
       " {' Okay.': 'fear'},\n",
       " {' As per you, what are the three important things that one should consider before joining any': 'joy'},\n",
       " {' organization as a fresher?': 'fear'},\n",
       " {' So, firstly, the one should look if there is a lot to learn from the company.': 'joy'},\n",
       " {' I mean, there should be a very steep growing curve in the company.': 'fear'},\n",
       " {' Secondly, there should be the colleagues and everything': 'anger'},\n",
       " {' should be very frank so that they help you in every way.': 'fear'},\n",
       " {' And thirdly, for me, there should be a brand name': 'fear'},\n",
       " {' so that there is a satisfaction that, yes,': 'fear'},\n",
       " {\" I've achieved a level and now I can go to the next level.\": 'fear'},\n",
       " {' Okay.': 'fear'},\n",
       " {' Technically, what gives you your offset impact?': 'joy'},\n",
       " {' So, technically, the latest, I want to go with latest technical skills, like not obsolete': 'fear'},\n",
       " {' technologies, but the latest technologies.': 'fear'},\n",
       " {' So, how does DCS fit into your requirement?': 'sadness'},\n",
       " {' So DCS changes its technologies according to the needs of the people of the R.': 'fear'},\n",
       " {' So there is no fixed technology that they use. They use according to their clients, which is very well.': 'joy'},\n",
       " {' Which are the major clients of these years?': 'sadness'},\n",
       " {' Can you name three or both of them?': 'fear'},\n",
       " {\" I'm sorry, so but I'm not aware of the clients.\": 'sadness'},\n",
       " {' Okay.': 'fear'},\n",
       " {' Sure. Anything that you want to ask?': 'fear'},\n",
       " {' So, will I be able to like fit in the company?': 'joy'},\n",
       " {' I mean, what do you think?': 'fear'},\n",
       " {' So will I be able to like fit in the company?': 'joy'},\n",
       " {' I mean what do you think?': 'fear'},\n",
       " {' Will you be able to fit into the company?': 'joy'},\n",
       " {' Yes sir.': 'joy'},\n",
       " {' Yeah.': 'fear'},\n",
       " {' As per your own analysis you said you are a good team player and what requirements you said for a good job.': 'joy'},\n",
       " {' Yes sir.': 'joy'},\n",
       " {\" In case you have those qualities I'm sure you'll be able to fit into.\": 'joy'},\n",
       " {' Okay sir, thank you. Any more suggestions for me?': 'joy'},\n",
       " {' No, nothing more.': 'fear'},\n",
       " {' Hervinsor will finally give his remarks.': 'anger'},\n",
       " {' Okay, thank you sir.': 'joy'},\n",
       " {' All the best.': 'fear'},\n",
       " {' Right.': 'fear'},\n",
       " {' Thank you sir.': 'joy'},\n",
       " {' Got it?': 'fear'},\n",
       " {' Yes sir.': 'joy'},\n",
       " {' What is your basically the aim?': 'fear'},\n",
       " {' You want to go in the software companies or anything more than that?': 'joy'},\n",
       " {' No sir, I want to go in the software companies that is running.': 'joy'},\n",
       " {' Okay.': 'fear'},\n",
       " {' If you are not able to go for any other studies or entrepreneurship like?': 'fear'},\n",
       " {' No, so entrepreneurship no, but the highest studies, many of the companies, TCS also provides like simultaneously higher studies, so that may': 'joy'},\n",
       " {' also be a very good option.': 'joy'},\n",
       " {' For example, you have got the offer from TCS.': 'joy'},\n",
       " {' At the same time, meanwhile, getting the better offer than TCS from another organization which is not tier 1 organization but': 'fear'},\n",
       " {' tier 2 organization but the package is just double of what we are offering then what we will': 'love'},\n",
       " {' do.': 'fear'},\n",
       " {' So, I compare both the companies in terms of the different we have told that TCS is': 'sadness'},\n",
       " {' tier 1 and you have got the offer from T2. It may be a startup or mid-sized company.': 'joy'},\n",
       " {' But the package, for example, we are giving you product, they are giving you a product.': 'fear'},\n",
       " {' In that case, what do you do?': 'fear'},\n",
       " {' So I choose TCS only because TCS is almost 150 years old company.': 'fear'},\n",
       " {' So it has a very good job security.': 'joy'},\n",
       " {' And as I cannot really trust her startup': 'fear'},\n",
       " {' because they are new in the industry.': 'fear'},\n",
       " {\" And that's why there is,\": 'fear'},\n",
       " {' there might be some trust issues.': 'fear'},\n",
       " {\" Let's get some help from you.\": 'fear'},\n",
       " {' So job security is more important than salutes.': 'joy'},\n",
       " {' If you will not perform well in the thesis also you can get the job in security in the': 'joy'},\n",
       " {' thesis also.': 'fear'},\n",
       " {' So but I will perform good and like from my end there will be no complaints from': 'anger'},\n",
       " {' Yeah, sorry.': 'sadness'},\n",
       " {' Good afternoon sir.': 'joy'},\n",
       " {' Good afternoon.': 'joy'},\n",
       " {' Which domain you will compatible?': 'joy'},\n",
       " {' Sir, of course, objects programming.': 'joy'},\n",
       " {' C++, DbNs, yes sir.': 'anger'},\n",
       " {' So give me a concept to implement this neck and leg. To implement snakes and ladders. I want to': 'fear'},\n",
       " {' I just do this. But I need only logic right not reporting a portal.': 'sadness'},\n",
       " {\" I'm going to make a video of the video.\": 'joy'},\n",
       " {' I have to go to the right direction.': 'fear'},\n",
       " {\" Yes, sir, it's a little rough.\": 'joy'},\n",
       " {' So we can analyze that you are going in a right direction.': 'fear'},\n",
       " {' Okay, sir.': 'joy'},\n",
       " {' So first we will build like a list, for example, of how many columns are there.': 'fear'},\n",
       " {' For example, I take a list of 50, the maximum we go to 50 and then now we take dice variable in which we will': 'fear'},\n",
       " {' take a random function with the help of random function we can derive a number between 1 to 6': 'fear'},\n",
       " {' and for the first for the first move if the number random number is 6 then we can move like we can keep a counter of the player. So we can increase': 'fear'},\n",
       " {' the counter with the number that comes in the dice and then we can now pre-defined the': 'fear'},\n",
       " {' snakes for example if at if we reach 5 then the the counter should like increase by 10 blocks. So the counter value increase by 10': 'fear'},\n",
       " {' blocks that is the ladder and this way we can like read a finalist.': 'anger'},\n",
       " {' One last question is how you will determine whether to you have to': 'fear'},\n",
       " {' increment its dice value means you want to use its increasing the counter value.': 'joy'},\n",
       " {' In form of ladder or you have to': 'anger'},\n",
       " {' decrement the counter value in form of': 'anger'},\n",
       " {' us.': 'fear'},\n",
       " {' So how you will do it?': 'fear'},\n",
       " {' My name.': 'fear'},\n",
       " {' So with the helper functions for': 'fear'},\n",
       " {' example of the dice value for if': 'fear'},\n",
       " {' if the dice value or the that': 'fear'},\n",
       " {' block value in which the': 'anger'},\n",
       " {' counter is the right now is a': 'fear'},\n",
       " {' five.': 'fear'},\n",
       " {' So I have assigned the five': 'fear'},\n",
       " {' already that five is a ladder.': 'fear'},\n",
       " {' So then it will increase and for example, if 12 is a snake,': 'fear'},\n",
       " {\" then I've already defined that 12 at 12,\": 'joy'},\n",
       " {' you need to decrement the value by, for example, 5 or whatever.': 'anger'},\n",
       " {\" So I will predefined, I'm very well predefined these values.\": 'joy'},\n",
       " {\" So I can use a dictionary to, like if I'm doing in Python then I can use it.\": 'joy'},\n",
       " {' And if we are using C then then CC was Java.': 'anger'},\n",
       " {\" They have the V doesn't have any dictionary.\": 'joy'},\n",
       " {' Then so we can use an array of arrays and then like make a dictionary with the help of a race.': 'joy'},\n",
       " {' Okay.': 'fear'},\n",
       " {' Yes.': 'fear'},\n",
       " {' Can we use switch or not there?': 'fear'},\n",
       " {' Switch.': 'fear'},\n",
       " {' Yes.': 'fear'},\n",
       " {' But so we can use.': 'fear'},\n",
       " {' But it is too long like we will have to write the code many times in switch.': 'sadness'},\n",
       " {' Why many times we can define a switch in a global or anywhere.': 'fear'},\n",
       " {' Then we can use it.': 'fear'},\n",
       " {' Visual switch for us,': 'anger'},\n",
       " {' NAKAN switch for a ladder 2 subject switches.': 'fear'},\n",
       " {' We can use yes, so that we can.': 'fear'},\n",
       " {' Okay, so what to mean by the in-cap solution is the Vianachancer is correct.': 'joy'},\n",
       " {' So, partially it is correct, it is used for data': 'sadness'},\n",
       " {' hiding, but more data security.': 'fear'},\n",
       " {' So, in a class it is implemented using access modifiers like public': 'anger'},\n",
       " {' protected private and there is a default access': 'fear'},\n",
       " {' specifiers as well.': 'joy'},\n",
       " {' So, using these we can define the scope of the variables or the functions.': 'fear'},\n",
       " {' Like if it is public then it can be used all through and if it is protected then only the': 'fear'},\n",
       " {' subclasses can use it and if private then only the current class can use it.': 'fear'},\n",
       " {' What do you mean by storage classes?': 'fear'},\n",
       " {' Storage classes.': 'fear'},\n",
       " {' So I am not able to recall.': 'fear'},\n",
       " {' What are you all the best?': 'fear'},\n",
       " {' Thank you so much.': 'fear'},\n",
       " {' I explore more and more,': 'joy'},\n",
       " {' TCS technical individual questions.': 'sadness'},\n",
       " {' They are basically mainly from CNC plus plus.': 'joy'},\n",
       " {\" Okay sir, I'll keep that in mind. Thank you so much sir.\": 'joy'},\n",
       " {' Thank you sir.': 'joy'},\n",
       " {' From my side and the ratters are interviewed by the mark for you definitely you are': 'joy'},\n",
       " {' the good candidate that we have already observed many times. Technical knowledge I have not': 'joy'},\n",
       " {' checked. You know your rate of departments, CAC will check it out.': 'fear'},\n",
       " {' But, uh, you can easily correct the process?': 'fear'},\n",
       " {' Okay, thank you so much sir.': 'joy'},\n",
       " {' Uh, uh, when you are, uh, learn about your thought process, then at least it should be justified': 'fear'},\n",
       " {' when you are giving the interviews.': 'fear'},\n",
       " {' Yes, sir.': 'joy'},\n",
       " {' That is very important.': 'joy'},\n",
       " {' If they feel that you want to come, but you cannot come, then then there is a': 'joy'},\n",
       " {' task that they can drop you.': 'fear'},\n",
       " {' Either you are a good candidate or the best.': 'joy'},\n",
       " {' For example, Google wants to have somebody or they will find the candidate which is': 'fear'},\n",
       " {' having the capabilities to get a corrode package in an': 'fear'},\n",
       " {' am right. But they have the doubt that no doubt is the best but they have the doubt that': 'joy'},\n",
       " {' either he will join or not then might be they can draw. So, that end of the condition': 'fear'},\n",
       " {' in the interview at least will not be so case.': 'fear'},\n",
       " {' Okay, I will keep that in mind.': 'fear'},\n",
       " {' So thank you.': 'fear'},\n",
       " {' All right, all set, right?': 'fear'},\n",
       " {' Okay, sir.': 'joy'},\n",
       " {' Thank you.': 'fear'},\n",
       " {' Thank you, sir.': 'joy'}]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_speech(text_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "114b792fd3786b6575d0460937c918251b05a94eee91cfbf04c710c56ed0b84d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
